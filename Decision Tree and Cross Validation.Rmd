---
title: "Decision Tree and Cross Validation"
author: "Suhail Shaikh"
date: "12/19/2019"
output:
  html_document: default
  pdf_document: default
  word_document: default
---

### Q)  This dataset is used to determine whether a wine quality is over 7. We have mapped the wine quality scores for you to binary classes of 0 and 1. Wine scores from 0 to 6 (inclusive) are mapped to 0, wine scores of 7 and above are mapped to 1. You will be performing binary classification on the dataset. The dataset is extracted from the UCI machine learning repository. Each line of this dataset describes a wine, using 12 columns: the firrst 11 describe the wines characteristics (details), and the last column is a ground truth label for the quality of the wine (0/1). Construct the best possible decision tree to predict the wine quality score. Explain how you have constructed your tree in details. Evaluate the performance of your decision tree using 10-fold cross validation. In a nutshell, you will first make a split of the provided data into 10 parts. Then hold out 1 part as the test set and use the remaining 9 parts for training. Train your decision tree using the training set and use the trained decision tree to classify entries in the test set. Repeat this process for all 10 parts, so that each entry will be used as the test set exactly once. To get the final accuracy value, take the average of the 10 folds accuracies (or other evaluation measures required).
```{r a}

library(readxl)

library(readxl)
##########################reading file#########################################
wineData <- read.csv("wineData.csv")
str(wineData)
###############################changing data type to factor for classification problem#####################################
wineData$quality <- as.factor(wineData$quality)
summary(wineData)
#starting Cross validation
set.seed(1234)
################################installing libraries##########################################################################
library(MASS)
library(caret)
library(caTools)


library(caret)
# building a decision tree
library(caTools)
pointer <- sample.split(Y = wineData$quality, SplitRatio = .7)
train_dt <- wineData[pointer,]
test_dt <- wineData[!pointer,]

#model building
library(rpart)
mod_dt <- rpart(quality~., data = train_dt, method = "class", parms = list(split="gini"))
plot(mod_dt$cptable)
#there is not much of a difference when we use gini, information gain or ctree to construct a tree, hence we are taking gini as a final variable.
#mod_dt$cptable expression list outs the cp values for the tree. We select out the minimum CP value for which the xerror is minimum.

# parameter tuning of decision tree,
# we are using two parameters to tune decision tree namely cp value and minsplit. we have fixed cp value to .01(obtained from model) and running a for loop 
# for multiple time to obtain optimum minsplit value.
#function for accuracy prediction.............
accuracy_tune <- function(var){
  predict_withdt <- predict(var, test_dt, type = "class")
  frq <- table(predict_withdt, test_dt$quality)
  accuracy_val <- sum(diag(frq))/sum(frq)
  accuracy_val
}
##############for loop for determine accuracy for large range min split#################

paratunerange <- c(20:100)
count<-1
accuracy.vector<-c()
for (i in paratunerange) {
  
mod_dt <- rpart(quality~., data = train_dt, method = "class", control = rpart.control(minsplit = i,cp = 0.01))
accuracy.vector[count] <- accuracy_tune(mod_dt)
count<-count+1
}
accuracy.vector
plot(paratunerange,accuracy.vector)
lines(accuracy.vector)
max <-max(accuracy.vector)
index = which(accuracy.vector==max)+19
index 
####### This suggest that this tree gives out maximum accuracy at minsplit values of 20,21,22,23,24,25,26,27,28,29,30,31,32,33,34.
### max accuracy is 81.27%

######################Using Cross Validation Technique to determine Accuracy#############################################33


winedata<-wineData[sample(nrow(wineData)),] 
k <- 10
nmethod <- 1
folds <- cut(seq(1,nrow(winedata)),breaks=k,labels=FALSE) 
models.err <- matrix(-1,k,nmethod, dimnames=list(paste0("Fold", 1:k), c("rpart")))

for(i in 1:k)
{
  testIndexes <- which(folds==i, arr.ind=TRUE)
  test_DT <- winedata[testIndexes, ]
  train_DT <- winedata[-testIndexes, ]
  
  pntr <- sample(2, nrow(train_DT), replace = T, prob = c(0.7, 0.3))
  train_CV <- train_DT[pntr == 1, ]
  Validation_CV <- train_DT[pntr == 2, ]
  
  pr.err <- c()
    library(rpart)
    wine_rpart <- rpart(quality~., data = train_CV, method="class", control = rpart.control(minsplit = 10, cp = 0.01))
    predicted <- predict(wine_rpart, newdata = Validation_CV, type = "class")
    pr.err <- c(pr.err,mean(Validation_CV$quality != predicted))
}
mean(pr.err)

#This cross validation suggest that we have received 20% error from 10 fold cross validation which is in tune with previous accuracy obtained with decision tree.

```
